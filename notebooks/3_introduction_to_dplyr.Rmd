---
title: "Using dplyr to manipulate data"
output: html_notebook
---

#Use select, filter, arrange, summarize, group_by and the pipe with dplyr

The dplyr package is part of the often used tidyverse. The following part of this R Notebook takes bits and pieces from the vignette about dplyr. This way you can try it out yourself.

```{r}
library(dplyr)
vignette("dplyr",package="dplyr")
```

This document introduces you to dplyr’s basic set of tools, and shows you how to apply them to data frames. dplyr also supports databases via the dbplyr package, once you’ve installed, read vignette("dbplyr") to learn more.

##Data: nycflights13

To explore the basic data manipulation verbs of dplyr, we’ll use nycflights13::flights. This dataset contains all 336776 flights that departed from New York City in 2013. 

```{r}
library(nycflights13)
# what are the dimensions of the flights tibble?
# dim(flights)[1] == rows
# dim(flights)[2] == columns
dim(flights)
```

```{r}
# show the content of flights
flights
```
Note that nycflights13::flights is a tibble, a modern reimagining of the data frame. It’s particularly useful for large datasets because it only prints the first few rows. You can learn more about tibbles at http://tibble.tidyverse.org; in particular you can convert data frames to tibbles with as_tibble().

##Single table verbs

Dplyr aims to provide a function for each basic verb of data manipulation:

* `filter()` to select cases based on their values.
* `arrange()` to reorder the cases.
* `select()` and `rename()` to select variables based on their names.
* `mutate()` and `transmute()` to add new variables that are functions of existing variables.
* `summarise()` to condense multiple values to a single value.
* `sample_n()` and `sample_frac()` to take random samples.

##Filter rows with filter()

filter() allows you to select a subset of rows in a data frame. Like all single verbs, the first argument is the tibble (or data frame). The second and subsequent arguments refer to variables within that data frame, selecting rows where the expression is TRUE.

For example, we can select all flights on January 1st with:

```{r}
# Multiple conditions are separated with comma's, (== and) 
# or with | (== or)
# try other filters too
filter(flights, month == 1, day == 1)
```
This is rougly equivalent to this base R code:

```{r}
flights[flights$month == 1 & flights$day == 1, ]
```

##Arrange rows with arrange()
`arrange()` works similarly to `filter()` except that instead of filtering or selecting rows, it reorders them. It takes a data frame, and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns:

```{r}
# try other orders too
arrange(flights, year, month, day)
```
Use desc() to order a column in descending order:

```{r}
arrange(flights, desc(arr_delay))
```


## Select columns with select()
Often you work with large datasets with many columns but only a few are actually of interest to you. select() allows you to rapidly zoom in on a useful subset using operations that usually only work on numeric variable positions:

Select columns by name:
```{r}
select(flights, year, month, day)
```

Select all columns between year and day (inclusive):
```{r}
select(flights, year:day)
```

Select all columns except those from year to day (inclusive):
```{r}
select(flights, -(year:day))
```

There are a number of helper functions you can use within `select()`, like `starts_with()`, `ends_with()`, `matches()` and `contains()`. These let you quickly match larger blocks of variables that meet some criterion. See ?select for more details.

You can rename variables with `select()` by using named arguments:
```{r}
select(flights, tail_num = tailnum)
```

But because `select()` drops all the variables not explicitly mentioned, it’s not that useful. Instead, use `rename()`:

```{r}
rename(flights, tail_num = tailnum)
```

##Add new columns with mutate()
Besides selecting sets of existing columns, it’s often useful to add new columns that are functions of existing columns. This is the job of `mutate()`:

```{r}
mutate(flights,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60
)
```
dplyr::mutate() is similar to the base transform(), but allows you to refer to columns that you’ve just created:

```{r}
mutate(flights,
  gain = arr_delay - dep_delay,
  gain_per_hour = gain / (air_time / 60)
)
```
##Piping

The dplyr API is functional in the sense that function calls don’t have side-effects. You must always save their results. This doesn’t lead to particularly elegant code, especially if you want to do many operations at once. You either have to do it step-by-step:
```{r}
a1 <- group_by(flights, year, month, day)
a2 <- select(a1, arr_delay, dep_delay)
a3 <- summarise(a2,
  arr = mean(arr_delay, na.rm = TRUE),
  dep = mean(dep_delay, na.rm = TRUE))
a4 <- filter(a3, arr > 30 | dep > 30)
a4
```

Or if you don’t want to name the intermediate results, you need to wrap the function calls inside each other:
```{r}
filter(
  summarise(
    select(
      group_by(flights, year, month, day),
      arr_delay, dep_delay
    ),
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ),
  arr > 30 | dep > 30
)

```

This is difficult to read because the order of the operations is from inside to out. Thus, the arguments are a long way away from the function. To get around this problem, dplyr provides the %>% operator from magrittr. x %>% f(y) turns into f(x, y) so you can use it to rewrite multiple operations that you can read left-to-right, top-to-bottom:

```{r}
flights %>%                        # use the output of flights as an input for group_by
  group_by(year, month, day) %>%   # use the output of group_by as input for select
  select(arr_delay, dep_delay) %>% # output of select is input for summarize
  summarise(
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ) %>%                            # output of summarize is input of filter
  filter(arr > 30 | dep > 30)

```
## Randomly sample rows with sample_n() and sample_frac()
You can use sample_n() and sample_frac() to take a random sample of rows: use sample_n() for a fixed number and sample_frac() for a fixed fraction.

The following code will give a sample of 10 rows:
```{r}
sample_n(flights, 10)
```

And this way you will get 1 percent of the rows.
```{r}
sample_frac(flights, 0.01)
```

Use replace = TRUE to perform a bootstrap sample. If needed, you can weight the sample with the weight argument.

Another often used implementation of sample_fraq is splitting the dataset in a training and test set. A model is created using the training set, and is scored using the test set.

```{r}
#If you do not have an ID per row, use the following code to create an ID
flights <- flights %>% mutate(id = row_number())
#Check IDs
head(flights$id)
#Create training set
flights.train <- flights %>% sample_frac(.7)
#Create test set
flights.test  <- anti_join(flights, flights.train, by = 'id')
cat("rowcount of training set: ", nrow(flights.train),"\n")
cat("rowcount of test set:     ", nrow(flights.test),"\n")
cat("total rowcount:           ", nrow(flights),"\n")

```

Another way to accomplish the same, without using dplyr:
```{r}
# seq_len creates a vector of numbers from one to provided number
seq_len(10)
# first get the number of rows in the dataset
rowcount <- nrow(flights)
# now create a vector of numbers representing each row:
rownumbers <- seq_len(rowcount)
# now create a sequence of training rows:
trainrows <- sample(rownumbers, floor(rowcount * 0.7))
# the train set will be the set selected with trainrows
flights.train <- flights[trainrows,]
# the test set will be the set with trainrows excluded (minus sigh)
flights.test <- flights[-trainrows,]
cat("rowcount of training set: ", nrow(flights.train),"\n")
cat("rowcount of test set:     ", nrow(flights.test),"\n")
cat("total rowcount:           ", nrow(flights),"\n")

```

